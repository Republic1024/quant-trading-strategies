# %%
# å¤šè‚¡ç¥¨é‡åŒ–åˆ†æå®Œæ•´æ•™ç¨‹
# æ•°æ®ï¼š8åªç§‘æŠ€è‚¡ 2023-2025å¹´æ•°æ® (AAPL, MSFT, GOOGL, AMZN, NVDA, TSLA, META, NFLX)

# --- å¯¼å…¥å¿…è¦åº“ ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from datetime import datetime, timedelta
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®æ˜¾ç¤ºé€‰é¡¹
pd.set_option('display.max_columns', None)
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("=== å¤šè‚¡ç¥¨é‡åŒ–åˆ†æç³»ç»Ÿ ===")
print("åˆ†æè‚¡ç¥¨: AAPL, MSFT, GOOGL, AMZN, NVDA, TSLA, META, NFLX")
print("æ—¶é—´èŒƒå›´: 2023-01-01 è‡³ 2025-08-30")

# %%
# --- é…ç½®å‚æ•° ---
TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'TSLA', 'META', 'NFLX']
START_DATE = '2023-01-01'
END_DATE = '2025-08-30'

# --- æ•°æ®è·å–å’Œé¢„å¤„ç† ---
print("æ­£åœ¨ä¸‹è½½æ•°æ®...")
df_data = yf.download(TICKERS, start=START_DATE, end=END_DATE, progress=False)

# æ£€æŸ¥æ•°æ®ç»“æ„
print(f"æ•°æ®å½¢çŠ¶: {df_data.shape}")
print(f"æ•°æ®åˆ—: {df_data.columns.levels[0].tolist()}")
print(f"è‚¡ç¥¨ä»£ç : {df_data.columns.levels[1].tolist()}")

# æå–æ”¶ç›˜ä»·æ•°æ®
df_prices = df_data['Close'].copy()
df_prices = df_prices.dropna()  # åˆ é™¤ç¼ºå¤±å€¼

print(f"\næ”¶ç›˜ä»·æ•°æ®å½¢çŠ¶: {df_prices.shape}")
print("å‰5è¡Œæ•°æ®:")
df_prices.head()

# %%
# === 1. åŸºç¡€æ•°æ®ç»Ÿè®¡åˆ†æ ===
print("=== 1. åŸºç¡€æ•°æ®ç»Ÿè®¡åˆ†æ ===")

# åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
basic_stats = df_prices.describe()
print("åŸºç¡€ç»Ÿè®¡ä¿¡æ¯:")
print(basic_stats.round(2))

# ä»·æ ¼èŒƒå›´åˆ†æ
price_range = pd.DataFrame({
    'èµ·å§‹ä»·æ ¼': df_prices.iloc[0],
    'ç»“æŸä»·æ ¼': df_prices.iloc[-1],
    'æœ€é«˜ä»·': df_prices.max(),
    'æœ€ä½ä»·': df_prices.min(),
    'æ€»æ¶¨å¹…(%)': ((df_prices.iloc[-1] / df_prices.iloc[0] - 1) * 100).round(2)
})

print("\nä»·æ ¼å˜åŠ¨ç»Ÿè®¡:")
print(price_range)

# å¯è§†åŒ–ä»·æ ¼èµ°åŠ¿
plt.figure(figsize=(15, 10))
for i, ticker in enumerate(TICKERS):
    plt.subplot(2, 4, i + 1)
    normalized_prices = df_prices[ticker] / df_prices[ticker].iloc[0] * 100
    plt.plot(normalized_prices.index, normalized_prices, label=ticker, linewidth=2)
    plt.title(f'{ticker} æ ‡å‡†åŒ–ä»·æ ¼èµ°åŠ¿', fontsize=12)
    plt.ylabel('æ ‡å‡†åŒ–ä»·æ ¼')
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# %%
# === 2. æ”¶ç›Šç‡åˆ†æ ===
print("\n=== 2. æ”¶ç›Šç‡åˆ†æ ===")

# è®¡ç®—æ—¥æ”¶ç›Šç‡
df_returns = df_prices.pct_change().dropna()

# æ”¶ç›Šç‡ç»Ÿè®¡
return_stats = pd.DataFrame({
    'å¹´åŒ–æ”¶ç›Šç‡(%)': (df_returns.mean() * 252 * 100).round(2),
    'å¹´åŒ–æ³¢åŠ¨ç‡(%)': (df_returns.std() * np.sqrt(252) * 100).round(2),
    'å¤æ™®æ¯”ç‡': ((df_returns.mean() * 252) / (df_returns.std() * np.sqrt(252))).round(3),
    'æœ€å¤§å•æ—¥æ¶¨å¹…(%)': (df_returns.max() * 100).round(2),
    'æœ€å¤§å•æ—¥è·Œå¹…(%)': (df_returns.min() * 100).round(2),
    'æ­£æ”¶ç›Šäº¤æ˜“æ—¥(%)': ((df_returns > 0).mean() * 100).round(2)
})

print("æ”¶ç›Šç‡ç»Ÿè®¡:")
print(return_stats)

# æ”¶ç›Šç‡åˆ†å¸ƒå¯è§†åŒ–
plt.figure(figsize=(15, 10))
for i, ticker in enumerate(TICKERS):
    plt.subplot(2, 4, i + 1)
    plt.hist(df_returns[ticker] * 100, bins=50, alpha=0.7, edgecolor='black')
    plt.title(f'{ticker} æ—¥æ”¶ç›Šç‡åˆ†å¸ƒ', fontsize=12)
    plt.xlabel('æ—¥æ”¶ç›Šç‡ (%)')
    plt.ylabel('é¢‘æ¬¡')
    plt.axvline(df_returns[ticker].mean() * 100, color='red', linestyle='--',
                label=f'å‡å€¼: {df_returns[ticker].mean() * 100:.2f}%')
    plt.legend()
    plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# %%
# === 3. ç›¸å…³æ€§åˆ†æ ===
print("\n=== 3. ç›¸å…³æ€§åˆ†æ ===")

# è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
correlation_matrix = df_returns.corr()
print("è‚¡ç¥¨é—´æ”¶ç›Šç‡ç›¸å…³æ€§çŸ©é˜µ:")
print(correlation_matrix.round(3))

# ç›¸å…³æ€§çƒ­åŠ›å›¾
plt.figure(figsize=(10, 8))
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,
            square=True, linewidths=0.5, cbar_kws={"shrink": .5})
plt.title('è‚¡ç¥¨æ”¶ç›Šç‡ç›¸å…³æ€§çŸ©é˜µ', fontsize=16)
plt.tight_layout()
plt.show()


# è¯†åˆ«é«˜ç›¸å…³å’Œä½ç›¸å…³é…å¯¹
def get_correlation_pairs(corr_matrix, threshold_high=0.7, threshold_low=0.3):
    pairs = []
    stocks = corr_matrix.index

    for i in range(len(stocks)):
        for j in range(i + 1, len(stocks)):
            corr_val = corr_matrix.iloc[i, j]
            if corr_val > threshold_high:
                pairs.append((stocks[i], stocks[j], corr_val, 'é«˜ç›¸å…³'))
            elif corr_val < threshold_low:
                pairs.append((stocks[i], stocks[j], corr_val, 'ä½ç›¸å…³'))

    return pd.DataFrame(pairs, columns=['è‚¡ç¥¨1', 'è‚¡ç¥¨2', 'ç›¸å…³ç³»æ•°', 'ç±»å‹'])


correlation_pairs = get_correlation_pairs(correlation_matrix)
if not correlation_pairs.empty:
    print("\nç‰¹æ®Šç›¸å…³æ€§é…å¯¹:")
    print(correlation_pairs.round(3))

# %%
# === 4. æŠ€æœ¯æŒ‡æ ‡è®¡ç®— ===
print("\n=== 4. æŠ€æœ¯æŒ‡æ ‡è®¡ç®— ===")


def calculate_technical_indicators(prices):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
    df_tech = pd.DataFrame(index=prices.index)

    for ticker in prices.columns:
        price_series = prices[ticker]

        # ç§»åŠ¨å¹³å‡çº¿
        df_tech[f'{ticker}_SMA_20'] = price_series.rolling(20).mean()
        df_tech[f'{ticker}_SMA_50'] = price_series.rolling(50).mean()
        df_tech[f'{ticker}_EMA_12'] = price_series.ewm(span=12).mean()
        df_tech[f'{ticker}_EMA_26'] = price_series.ewm(span=26).mean()

        # MACD
        df_tech[f'{ticker}_MACD'] = df_tech[f'{ticker}_EMA_12'] - df_tech[f'{ticker}_EMA_26']
        df_tech[f'{ticker}_MACD_Signal'] = df_tech[f'{ticker}_MACD'].ewm(span=9).mean()
        df_tech[f'{ticker}_MACD_Hist'] = df_tech[f'{ticker}_MACD'] - df_tech[f'{ticker}_MACD_Signal']

        # RSI
        delta = price_series.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df_tech[f'{ticker}_RSI'] = 100 - (100 / (1 + rs))

        # å¸ƒæ—å¸¦
        df_tech[f'{ticker}_BB_Middle'] = price_series.rolling(20).mean()
        bb_std = price_series.rolling(20).std()
        df_tech[f'{ticker}_BB_Upper'] = df_tech[f'{ticker}_BB_Middle'] + (bb_std * 2)
        df_tech[f'{ticker}_BB_Lower'] = df_tech[f'{ticker}_BB_Middle'] - (bb_std * 2)
        df_tech[f'{ticker}_BB_Position'] = ((price_series - df_tech[f'{ticker}_BB_Lower']) /
                                            (df_tech[f'{ticker}_BB_Upper'] - df_tech[f'{ticker}_BB_Lower']))

    return df_tech


# è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
df_technical = calculate_technical_indicators(df_prices)

# æ˜¾ç¤ºæœ€æ–°æŠ€æœ¯æŒ‡æ ‡
latest_tech = pd.DataFrame()
for ticker in TICKERS:
    latest_tech[ticker] = {
        'å½“å‰ä»·æ ¼': df_prices[ticker].iloc[-1],
        'RSI': df_technical[f'{ticker}_RSI'].iloc[-1],
        'MACD': df_technical[f'{ticker}_MACD'].iloc[-1],
        'å¸ƒæ—å¸¦ä½ç½®': df_technical[f'{ticker}_BB_Position'].iloc[-1],
        'ç›¸å¯¹20æ—¥å‡çº¿(%)': ((df_prices[ticker].iloc[-1] /
                             df_technical[f'{ticker}_SMA_20'].iloc[-1] - 1) * 100)
    }

latest_tech = pd.DataFrame(latest_tech).T
print("æœ€æ–°æŠ€æœ¯æŒ‡æ ‡:")
print(latest_tech.round(3))

# %%
# === 5. é£é™©æŒ‡æ ‡è®¡ç®— ===
print("\n=== 5. é£é™©æŒ‡æ ‡è®¡ç®— ===")


def calculate_risk_metrics(returns, prices):
    """è®¡ç®—é£é™©æŒ‡æ ‡"""
    risk_metrics = {}

    for ticker in returns.columns:
        ret_series = returns[ticker].dropna()
        price_series = prices[ticker].dropna()

        # åŸºç¡€é£é™©æŒ‡æ ‡
        annual_return = ret_series.mean() * 252
        annual_vol = ret_series.std() * np.sqrt(252)
        sharpe_ratio = annual_return / annual_vol if annual_vol != 0 else 0

        # æœ€å¤§å›æ’¤
        cumulative = (1 + ret_series).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        max_drawdown = drawdown.min()

        # VaRå’ŒCVaR (95%ç½®ä¿¡æ°´å¹³)
        var_95 = np.percentile(ret_series, 5)
        cvar_95 = ret_series[ret_series <= var_95].mean()

        # Sortinoæ¯”ç‡ (åªè€ƒè™‘ä¸‹è¡Œæ³¢åŠ¨)
        downside_returns = ret_series[ret_series < 0]
        downside_vol = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0
        sortino_ratio = annual_return / downside_vol if downside_vol != 0 else 0

        # ååº¦å’Œå³°åº¦
        skewness = ret_series.skew()
        kurtosis = ret_series.kurtosis()

        risk_metrics[ticker] = {
            'å¹´åŒ–æ”¶ç›Šç‡': annual_return,
            'å¹´åŒ–æ³¢åŠ¨ç‡': annual_vol,
            'å¤æ™®æ¯”ç‡': sharpe_ratio,
            'Sortinoæ¯”ç‡': sortino_ratio,
            'æœ€å¤§å›æ’¤': max_drawdown,
            'VaR_95%': var_95,
            'CVaR_95%': cvar_95,
            'ååº¦': skewness,
            'å³°åº¦': kurtosis
        }

    return pd.DataFrame(risk_metrics).T


# è®¡ç®—é£é™©æŒ‡æ ‡
risk_metrics = calculate_risk_metrics(df_returns, df_prices)
print("é£é™©æŒ‡æ ‡ç»Ÿè®¡:")
print(risk_metrics.round(4))

# é£é™©æ”¶ç›Šæ•£ç‚¹å›¾
plt.figure(figsize=(12, 8))
for ticker in TICKERS:
    annual_return = risk_metrics.loc[ticker, 'å¹´åŒ–æ”¶ç›Šç‡'] * 100
    annual_vol = risk_metrics.loc[ticker, 'å¹´åŒ–æ³¢åŠ¨ç‡'] * 100
    plt.scatter(annual_vol, annual_return, s=100, alpha=0.7, label=ticker)
    plt.annotate(ticker, (annual_vol, annual_return), xytext=(5, 5),
                 textcoords='offset points', fontsize=10)

plt.xlabel('å¹´åŒ–æ³¢åŠ¨ç‡ (%)')
plt.ylabel('å¹´åŒ–æ”¶ç›Šç‡ (%)')
plt.title('é£é™©-æ”¶ç›Šæ•£ç‚¹å›¾', fontsize=14)
plt.grid(True, alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()

# %%
# === 6. æŠ•èµ„ç»„åˆåˆ†æ ===
print("\n=== 6. æŠ•èµ„ç»„åˆåˆ†æ ===")

# ç­‰æƒé‡ç»„åˆ
equal_weight_portfolio = df_returns.mean(axis=1)


# è®¡ç®—å„ç§æƒé‡ç­–ç•¥
def optimize_portfolio_weights(returns, method='min_variance'):
    """è®¡ç®—æœ€ä¼˜æƒé‡"""
    cov_matrix = returns.cov()

    if method == 'min_variance':
        # æœ€å°æ–¹å·®æƒé‡
        inv_cov = np.linalg.pinv(cov_matrix.values)
        ones = np.ones((len(returns.columns), 1))
        weights = (inv_cov @ ones) / (ones.T @ inv_cov @ ones)
        return pd.Series(weights.flatten(), index=returns.columns)

    elif method == 'risk_parity':
        # é£é™©å¹³ä»·æƒé‡ (ç®€åŒ–ç‰ˆï¼š1/æ³¢åŠ¨ç‡æƒé‡)
        vols = returns.std()
        inv_vol_weights = (1 / vols) / (1 / vols).sum()
        return inv_vol_weights


# è®¡ç®—ä¸åŒç»„åˆç­–ç•¥
portfolio_strategies = {}

# ç­‰æƒé‡ç»„åˆ
equal_weights = pd.Series(1 / len(TICKERS), index=TICKERS)
portfolio_strategies['ç­‰æƒé‡'] = (df_returns * equal_weights).sum(axis=1)

# é£é™©å¹³ä»·ç»„åˆ
risk_parity_weights = optimize_portfolio_weights(df_returns, 'risk_parity')
portfolio_strategies['é£é™©å¹³ä»·'] = (df_returns * risk_parity_weights).sum(axis=1)

# æœ€å°æ–¹å·®ç»„åˆ
try:
    min_var_weights = optimize_portfolio_weights(df_returns, 'min_variance')
    portfolio_strategies['æœ€å°æ–¹å·®'] = (df_returns * min_var_weights).sum(axis=1)
except:
    print("æœ€å°æ–¹å·®ç»„åˆè®¡ç®—å¤±è´¥ï¼Œè·³è¿‡")

# ç»„åˆä¸šç»©æ¯”è¾ƒ
portfolio_performance = pd.DataFrame()
for strategy_name, strategy_returns in portfolio_strategies.items():
    portfolio_performance[strategy_name] = {
        'å¹´åŒ–æ”¶ç›Šç‡(%)': strategy_returns.mean() * 252 * 100,
        'å¹´åŒ–æ³¢åŠ¨ç‡(%)': strategy_returns.std() * np.sqrt(252) * 100,
        'å¤æ™®æ¯”ç‡': (strategy_returns.mean() * 252) / (strategy_returns.std() * np.sqrt(252)),
        'æœ€å¤§å›æ’¤(%)': ((1 + strategy_returns).cumprod() /
                        (1 + strategy_returns).cumprod().expanding().max() - 1).min() * 100
    }

portfolio_performance = pd.DataFrame(portfolio_performance).T
print("æŠ•èµ„ç»„åˆç­–ç•¥æ¯”è¾ƒ:")
print(portfolio_performance.round(3))

# ç»„åˆæƒé‡æ˜¾ç¤º
weights_comparison = pd.DataFrame({
    'ç­‰æƒé‡': equal_weights,
    'é£é™©å¹³ä»·': risk_parity_weights
})

if 'min_var_weights' in locals():
    weights_comparison['æœ€å°æ–¹å·®'] = min_var_weights

print("\nç»„åˆæƒé‡åˆ†é…:")
print((weights_comparison * 100).round(2))

# %%
# === 7. é…å¯¹äº¤æ˜“åˆ†æ ===
print("\n=== 7. é…å¯¹äº¤æ˜“åˆ†æ ===")


def find_cointegrated_pairs(prices, significance_level=0.05):
    """å¯»æ‰¾åæ•´é…å¯¹"""
    from statsmodels.tsa.stattools import coint

    n = len(prices.columns)
    pvalue_matrix = np.ones((n, n))
    pairs = []

    for i in range(n):
        for j in range(i + 1, n):
            stock1, stock2 = prices.columns[i], prices.columns[j]
            try:
                _, pvalue, _ = coint(prices[stock1], prices[stock2])
                pvalue_matrix[i, j] = pvalue

                if pvalue < significance_level:
                    pairs.append((stock1, stock2, pvalue))
            except:
                continue

    return pairs, pvalue_matrix


# å¯»æ‰¾åæ•´é…å¯¹
try:
    cointegrated_pairs, pvalue_matrix = find_cointegrated_pairs(df_prices)

    if cointegrated_pairs:
        pairs_df = pd.DataFrame(cointegrated_pairs,
                                columns=['è‚¡ç¥¨1', 'è‚¡ç¥¨2', 'På€¼'])
        pairs_df = pairs_df.sort_values('På€¼')
        print("åæ•´è‚¡ç¥¨é…å¯¹ (På€¼ < 0.05):")
        print(pairs_df.round(4))

        # åˆ†ææœ€ä½³é…å¯¹
        if len(pairs_df) > 0:
            best_pair = pairs_df.iloc[0]
            stock1, stock2 = best_pair['è‚¡ç¥¨1'], best_pair['è‚¡ç¥¨2']

            # è®¡ç®—ä»·å·®å’ŒZ-score
            spread = df_prices[stock1] - df_prices[stock2]
            z_score = (spread - spread.rolling(60).mean()) / spread.rolling(60).std()

            print(f"\næœ€ä½³é…å¯¹åˆ†æ: {stock1} vs {stock2}")
            print(f"åæ•´På€¼: {best_pair['På€¼']:.4f}")
            print(f"å½“å‰Z-Score: {z_score.iloc[-1]:.3f}")

            # å¯è§†åŒ–é…å¯¹
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))

            # æ ‡å‡†åŒ–ä»·æ ¼èµ°åŠ¿
            ax1.plot(df_prices.index, df_prices[stock1] / df_prices[stock1].iloc[0],
                     label=stock1, linewidth=2)
            ax1.plot(df_prices.index, df_prices[stock2] / df_prices[stock2].iloc[0],
                     label=stock2, linewidth=2)
            ax1.set_title(f'é…å¯¹è‚¡ç¥¨æ ‡å‡†åŒ–ä»·æ ¼èµ°åŠ¿: {stock1} vs {stock2}')
            ax1.legend()
            ax1.grid(True, alpha=0.3)

            # Z-Scoreèµ°åŠ¿
            ax2.plot(z_score.index, z_score, color='purple', linewidth=2)
            ax2.axhline(y=2, color='r', linestyle='--', alpha=0.7, label='è¶…ä¹°çº¿ (+2)')
            ax2.axhline(y=-2, color='g', linestyle='--', alpha=0.7, label='è¶…å–çº¿ (-2)')
            ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)
            ax2.fill_between(z_score.index, -2, 2, alpha=0.2, color='gray', label='æ­£å¸¸åŒºé—´')
            ax2.set_title('é…å¯¹äº¤æ˜“Z-Scoreä¿¡å·')
            ax2.set_ylabel('Z-Score')
            ax2.legend()
            ax2.grid(True, alpha=0.3)

            plt.tight_layout()
            plt.show()
    else:
        print("æœªæ‰¾åˆ°æ˜¾è‘—çš„åæ•´é…å¯¹")

except ImportError:
    print("éœ€è¦å®‰è£… statsmodels åº“æ¥è¿›è¡Œåæ•´æ£€éªŒ")
except Exception as e:
    print(f"é…å¯¹äº¤æ˜“åˆ†æå‡ºé”™: {e}")

# %%
# === 8. åŠ¨é‡å’Œåè½¬ç­–ç•¥åˆ†æ ===
print("\n=== 8. åŠ¨é‡å’Œåè½¬ç­–ç•¥åˆ†æ ===")

# è®¡ç®—ä¸åŒæœŸé—´çš„åŠ¨é‡æŒ‡æ ‡
momentum_periods = [5, 10, 20, 60]
momentum_scores = pd.DataFrame(index=df_prices.index)

for period in momentum_periods:
    for ticker in TICKERS:
        col_name = f'{ticker}_momentum_{period}d'
        momentum_scores[col_name] = df_prices[ticker].pct_change(period)

# æœ€æ–°åŠ¨é‡è¯„åˆ†
latest_momentum = pd.DataFrame()
for ticker in TICKERS:
    latest_momentum[ticker] = {
        f'{period}æ—¥åŠ¨é‡(%)': momentum_scores[f'{ticker}_momentum_{period}d'].iloc[-1] * 100
        for period in momentum_periods
    }

latest_momentum = pd.DataFrame(latest_momentum).T
print("æœ€æ–°åŠ¨é‡è¯„åˆ†:")
print(latest_momentum.round(2))


# åŠ¨é‡æ’åç­–ç•¥å›æµ‹
def momentum_strategy_backtest(returns, prices, lookback=20, rebalance=20):
    """åŠ¨é‡ç­–ç•¥å›æµ‹"""
    strategy_returns = []

    for i in range(lookback + rebalance, len(returns)):
        # è®¡ç®—è¿‡å»lookbackå¤©çš„æ”¶ç›Šç‡
        end_date = returns.index[i - rebalance]
        start_date = returns.index[i - rebalance - lookback]

        period_returns = prices.loc[end_date] / prices.loc[start_date] - 1

        # é€‰æ‹©æ’åå‰3çš„è‚¡ç¥¨ç­‰æƒé…ç½®
        top_stocks = period_returns.nlargest(3).index

        # è®¡ç®—æœªæ¥rebalanceå¤©çš„ç»„åˆæ”¶ç›Š
        future_returns = returns.iloc[i - rebalance:i][top_stocks].mean(axis=1)
        strategy_returns.extend(future_returns.tolist())

    return pd.Series(strategy_returns)


# æ‰§è¡ŒåŠ¨é‡ç­–ç•¥å›æµ‹
momentum_strategy = momentum_strategy_backtest(df_returns, df_prices)

print(f"\nåŠ¨é‡ç­–ç•¥å›æµ‹ç»“æœ:")
print(f"ç­–ç•¥å¹´åŒ–æ”¶ç›Šç‡: {momentum_strategy.mean() * 252 * 100:.2f}%")
print(f"ç­–ç•¥å¹´åŒ–æ³¢åŠ¨ç‡: {momentum_strategy.std() * np.sqrt(252) * 100:.2f}%")
print(f"ç­–ç•¥å¤æ™®æ¯”ç‡: {(momentum_strategy.mean() * 252) / (momentum_strategy.std() * np.sqrt(252)):.3f}")

# %%
# === 9. ç»¼åˆè¯„åˆ†ç³»ç»Ÿ ===
print("\n=== 9. ç»¼åˆè¯„åˆ†ç³»ç»Ÿ ===")


def calculate_composite_score(prices, returns, technical_indicators):
    """è®¡ç®—ç»¼åˆè¯„åˆ†"""
    scores = pd.DataFrame(index=TICKERS)

    for ticker in TICKERS:
        # æŠ€æœ¯é¢è¯„åˆ† (0-100)
        rsi = technical_indicators[f'{ticker}_RSI'].iloc[-1]
        bb_pos = technical_indicators[f'{ticker}_BB_Position'].iloc[-1]
        macd = technical_indicators[f'{ticker}_MACD'].iloc[-1]
        macd_signal = technical_indicators[f'{ticker}_MACD_Signal'].iloc[-1]

        # RSIè¯„åˆ† (30-70ä¸ºä¸­æ€§ï¼Œè¿‡é«˜è¿‡ä½æ‰£åˆ†)
        if 30 <= rsi <= 70:
            rsi_score = 50 + (50 - abs(rsi - 50))
        else:
            rsi_score = max(0, 50 - abs(rsi - 50))

        # å¸ƒæ—å¸¦ä½ç½®è¯„åˆ†
        bb_score = max(0, min(100, bb_pos * 100))

        # MACDè¯„åˆ†
        macd_score = 60 if macd > macd_signal else 40

        # åŸºæœ¬é¢è¯„åˆ† (åŸºäºé£é™©è°ƒæ•´æ”¶ç›Š)
        annual_return = returns[ticker].mean() * 252
        annual_vol = returns[ticker].std() * np.sqrt(252)
        sharpe = annual_return / annual_vol if annual_vol > 0 else 0
        fundamental_score = min(100, max(0, 50 + sharpe * 20))

        # åŠ¨é‡è¯„åˆ†
        momentum_20d = (prices[ticker].iloc[-1] / prices[ticker].iloc[-21] - 1)
        momentum_score = min(100, max(0, 50 + momentum_20d * 200))

        # ç»¼åˆè¯„åˆ† (å„é¡¹æƒé‡)
        composite = (rsi_score * 0.2 + bb_score * 0.2 + macd_score * 0.2 +
                     fundamental_score * 0.3 + momentum_score * 0.1)

        scores.loc[ticker] = {
            'RSIè¯„åˆ†': rsi_score,
            'å¸ƒæ—å¸¦è¯„åˆ†': bb_score,
            'MACDè¯„åˆ†': macd_score,
            'åŸºæœ¬é¢è¯„åˆ†': fundamental_score,
            'åŠ¨é‡è¯„åˆ†': momentum_score,
            'ç»¼åˆè¯„åˆ†': composite
        }

    return scores.round(2)


# è®¡ç®—ç»¼åˆè¯„åˆ†
composite_scores = calculate_composite_score(df_prices, df_returns, df_technical)
composite_scores = composite_scores.sort_values('ç»¼åˆè¯„åˆ†', ascending=False)

print("è‚¡ç¥¨ç»¼åˆè¯„åˆ†æ’å:")
print(composite_scores)

# è¯„åˆ†å¯è§†åŒ–
plt.figure(figsize=(12, 8))
scores_for_plot = composite_scores['ç»¼åˆè¯„åˆ†'].values
tickers_for_plot = composite_scores.index
colors = ['green' if score >= 70 else 'orange' if score >= 50 else 'red' for score in scores_for_plot]

bars = plt.bar(tickers_for_plot, scores_for_plot, color=colors, alpha=0.7, edgecolor='black')
plt.axhline(y=70, color='green', linestyle='--', alpha=0.7, label='ä¼˜ç§€çº¿ (70)')
plt.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='åŠæ ¼çº¿ (50)')
plt.xlabel('è‚¡ç¥¨ä»£ç ')
plt.ylabel('ç»¼åˆè¯„åˆ†')
plt.title('è‚¡ç¥¨ç»¼åˆè¯„åˆ†æ’å', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3, axis='y')

# åœ¨æŸ±çŠ¶å›¾ä¸Šæ ‡æ³¨åˆ†æ•°
for bar, score in zip(bars, scores_for_plot):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,
             f'{score:.0f}', ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.show()

# %%
# === 10. æ€»ç»“æŠ¥å‘Š ===
print("\n" + "=" * 60)
print("=== å¤šè‚¡ç¥¨é‡åŒ–åˆ†ææ€»ç»“æŠ¥å‘Š ===")
print("=" * 60)

print(f"\nğŸ“Š æ•°æ®æ¦‚å†µ:")
print(f"â€¢ åˆ†æè‚¡ç¥¨: {', '.join(TICKERS)}")
print(f"â€¢ æ•°æ®æœŸé—´: {START_DATE} è‡³ {END_DATE}")
print(f"â€¢ äº¤æ˜“æ—¥æ•°: {len(df_prices)} å¤©")

print(f"\nğŸ† ä¸šç»©æ’å (æŒ‰æ€»æ”¶ç›Šç‡):")
total_returns = ((df_prices.iloc[-1] / df_prices.iloc[0] - 1) * 100).sort_values(ascending=False)
for i, (ticker, ret) in enumerate(total_returns.items(), 1):
    print(f"{i:2d}. {ticker}: {ret:+7.2f}%")

print(f"\nâš¡ ç»¼åˆè¯„åˆ†æ’å:")
for i, (ticker, score) in enumerate(composite_scores['ç»¼åˆè¯„åˆ†'].items(), 1):
    status = "ğŸŸ¢" if score >= 70 else "ğŸŸ¡" if score >= 50 else "ğŸ”´"
    print(f"{i:2d}. {ticker}: {score:5.1f} {status}")

print(f"\nğŸ’¡ æŠ•èµ„å»ºè®®:")
top_stocks = composite_scores.head(3).index.tolist()
print(f"â€¢ æ¨èå…³æ³¨: {', '.join(top_stocks)}")

high_risk_stocks = risk_metrics.nlargest(2, 'å¹´åŒ–æ³¢åŠ¨ç‡').index.tolist()
print(f"â€¢ é«˜é£é™©è‚¡ç¥¨: {', '.join(high_risk_stocks)}")

if 'cointegrated_pairs' in locals() and len(cointegrated_pairs) > 0:
    print(f"â€¢ é…å¯¹äº¤æ˜“æœºä¼š: {len(cointegrated_pairs)} ç»„")

print(f"\nğŸ“ˆ ç­–ç•¥å»ºè®®:")